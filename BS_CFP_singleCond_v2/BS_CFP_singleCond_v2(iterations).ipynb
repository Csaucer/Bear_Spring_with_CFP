{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2763f07",
   "metadata": {},
   "source": [
    "# BS_CFP_singleCond_v2\n",
    "\n",
    "#### This note book is designed with the same spatial and hydrological parameters as the BS_CFP_v1 model, except that the model here has a single, simplified conduit that is varied over iterations using pyKasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d760d483",
   "metadata": {},
   "source": [
    "## Import packages necessary to run CFPy, flopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "890ec2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charlie\\Anaconda3\\envs\\pyKasso2D_cfpy\\lib\\site-packages\\mplstereonet\\stereonet_axes.py:17: PendingDeprecationWarning: Overriding `Axes.cla` in StereonetAxes is pending deprecation in 3.6 and will be fully deprecated in favor of `Axes.clear` in the future. Please report this to the 'mplstereonet.stereonet_axes' author.\n",
      "  class StereonetAxes(LambertAxes):\n"
     ]
    }
   ],
   "source": [
    "##Import package dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import CFPy as cfpy\n",
    "import flopy as flopy\n",
    "import flopy.utils.binaryfile as bf\n",
    "import pykasso as pk\n",
    "path=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fbc09d",
   "metadata": {},
   "source": [
    "## Show Versions w/ line magic\n",
    "Show the versions of python and the imported packages being used in this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45ccad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e6b3b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2023-04-27T17:05:21.625438-05:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.16\n",
      "IPython version      : 8.10.0\n",
      "\n",
      "Compiler    : MSC v.1929 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 158 Stepping 13, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77c6ad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFPy      : 0.1\n",
      "flopy     : 3.3.6\n",
      "numpy     : 1.24.2\n",
      "pykasso   : 0.1.0\n",
      "pandas    : 1.5.3\n",
      "matplotlib: 3.7.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e607149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define helper functions\n",
    "def create_network():\n",
    "    \"\"\"\n",
    "    Create the network with pyKasso and process/export it with cfpy\n",
    "    \n",
    "    Keyword Arguments: yaml_file -- absolute path to settings file of pyKasso, str\n",
    "    \n",
    "    Return: validator object, valid network array\n",
    "    \"\"\"\n",
    "    # read in settings file\n",
    "    catchment = pk.SKS(yaml_settings_file=yaml_file)\n",
    "    \n",
    "    # compute karst networks from the given information\n",
    "    catchment.compute_karst_network()\n",
    "\n",
    "    # generate elevation data\n",
    "    # NOTE: elevation data has to have the same shape as the node network array!\n",
    "    shp = np.array(catchment.karst_simulations[-1].maps['karst'][-1]).shape\n",
    "   \n",
    "    # Set elevation of all nodes\n",
    "    elevs = np.ones(shp) * elev_nodes\n",
    "    \n",
    "    # validate the network from pyKasso\n",
    "    validator = cfpy.preprocessing.pyKassoValidator(network=catchment, elevations=elevs)\n",
    "    valid_network = validator.validate_network()\n",
    "    \n",
    "    # export the network\n",
    "    # the exported information can directly be included in the .nbr-file as input for CFPy\n",
    "    # notes on how to use the generated data with CFPy is given at the end of the notebook\n",
    "    # per default, the network is exported to \"CFPy_exported_network_for_NBR.txt\" in the active directory\n",
    "    validator.export_network()\n",
    "    \n",
    "    return validator, valid_network\n",
    "\n",
    "\n",
    "def position_to_index(x, y):\n",
    "    \"\"\"\n",
    "    Get the modflow (!) based index for a given geo position\n",
    "    \n",
    "    Keyword Arguments\n",
    "    x -- x position, m\n",
    "    y -- y position, m\n",
    "    \n",
    "    Return\n",
    "    column index, row index\n",
    "    \"\"\"\n",
    "    \n",
    "    col_idx = np.floor(x / delr) + 1\n",
    "    row_idx = n_rows - np.floor(y / delc)\n",
    "    \n",
    "    return col_idx, row_idx\n",
    "\n",
    "def store_results(number):\n",
    "    \"\"\"\n",
    "    Create a directory and put the current results there\n",
    "    \n",
    "    Keyword Arguments\n",
    "    number -- identifier of the current iteration, float or int\n",
    "    \n",
    "    Return\n",
    "    -\n",
    "    \"\"\"\n",
    "    \n",
    "    # define directory where to store the results\n",
    "    target_dir = os.path.join(path, f\"run_{number}\")\n",
    "    \n",
    "    # make sure the directory does not exist\n",
    "    if os.path.exists(target_dir):\n",
    "        raise Exception(f\"Directory {target_dir} exists already! Unable to write results\")\n",
    "        \n",
    "    # create directory\n",
    "    os.makedirs(target_dir)\n",
    "    \n",
    "    # get alle files that will be moved\n",
    "    files_to_move = glob.glob(\"NODE*\") + glob.glob(\"TUBE*\") \\\n",
    "                    + [f\"{modelname}.list\", f\"{modelname}.hds\", f\"{modelname}.cbc\"] \\\n",
    "                    + [f\"network_{number}.png\"] \\\n",
    "                    + glob.glob(\"*.nbr\") + glob.glob(\"*.coc\") + glob.glob(\"*.cfp\") + glob.glob(\"*.crch\")\n",
    "    \n",
    "    # move files to directory\n",
    "    for f in files_to_move:\n",
    "        source = os.path.join(path, f)\n",
    "        destination = os.path.join(target_dir, f)\n",
    "        shutil.move(source, destination)\n",
    "\n",
    "def clean_results():\n",
    "    \"\"\"\n",
    "    Remove all run-dictionaries\n",
    "    \n",
    "    Keyword Arguments\n",
    "    -\n",
    "    \n",
    "    Return\n",
    "    -\n",
    "    \"\"\"    \n",
    "    run_dirs = glob.glob(os.path.join(path, \"run_*\"))    \n",
    "    for rd in run_dirs:\n",
    "        shutil.rmtree(rd)\n",
    "        \n",
    "def plot_network(valid_network, number):\n",
    "    \"\"\"\n",
    "    Plot and save valid network array as png\n",
    "    \n",
    "    Keyword Arguments\n",
    "    valid_network -- valid network array\n",
    "    number -- identifier of the current iteration, float or int\n",
    "    \n",
    "    Return\n",
    "    -\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a figure \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # plot the array\n",
    "    im = plt.imshow(valid_network)\n",
    "    cb = plt.colorbar(im, shrink=0.3)\n",
    "    \n",
    "    # set descriptions\n",
    "    plt.xlabel(\"Spaltenindex\", size=14)\n",
    "    plt.ylabel(\"Reihenindex\", size =14)\n",
    "    cb.set_label(\"Höhe, m\", size=14)\n",
    "    \n",
    "    # save figure\n",
    "    plt.savefig(f'network_{number}.png')\n",
    "\n",
    "def create_nbr(validator):\n",
    "    \"\"\"\n",
    "    Create nbr file\n",
    "    \n",
    "    Keyword Arguments:\n",
    "      validator -- validator object\n",
    "    \n",
    "    Return: -\n",
    "    \"\"\"\n",
    "    # generate nbr file\n",
    "    validator.generate_nbr(\n",
    "        path = path,\n",
    "        nrows = n_rows,\n",
    "        ncols = n_cols,\n",
    "        nlays = n_lays,\n",
    "        nplanes = 1,\n",
    "        layer_elevations = lay_elevs_array\n",
    "    )\n",
    "\n",
    "def read_nbr():\n",
    "    \"\"\"\n",
    "    Read in nbr data\n",
    "    \n",
    "    Keyword Arguments: -\n",
    "    \n",
    "    Return: nbr data, conduits elevation\n",
    "    \"\"\"\n",
    "    # create nbr object\n",
    "    nbr = cfpy.nbr()\n",
    "\n",
    "    # read model layer/node and conduit layer/node elevations\n",
    "\n",
    "    # bot_elev has shape (n_layers, n_rows, n_cols)\n",
    "    # cond_elev has shape (n_conduit_layers, n_rows, n_cols)\n",
    "    # function looks for an .nbr-file, if none or more than one file is found, an error is raised\n",
    "    # make sure to only have one .nbr-file in the working directory\n",
    "    bot_elev, cond_elev = nbr.nbr_read()\n",
    "\n",
    "    # create nbr data\n",
    "    nbr_data = nbr.nbr(bot_elev, cond_elev)\n",
    "    \n",
    "    #return nbr_data, cond_elev\n",
    "    return nbr_data, [bot_elev, cond_elev]\n",
    "\n",
    "def create_pipe_data(p_num):\n",
    "    \"\"\"\n",
    "    Create nested list of pipe data. Assuming same characteristics for all pipes\n",
    "    \n",
    "    Keyword Arguments:\n",
    "      p_num -- pipe numbers, i.e. nbr_data[5]\n",
    "    \n",
    "    Return: pipe data\n",
    "    \"\"\"\n",
    "    # diameter\n",
    "    p_diameter = np.ones(len(p_num)) * DIA\n",
    "    p_diameter = p_diameter.tolist()\n",
    "\n",
    "    # tortuosity\n",
    "    p_tortuosity = np.ones(len(p_num)) * TOR\n",
    "    p_tortuosity = p_tortuosity.tolist()\n",
    "\n",
    "    # roughness height\n",
    "    p_rheight = np.ones(len(p_num)) * KC\n",
    "    p_rheight = p_rheight.tolist()\n",
    "\n",
    "    # lower critical reynolds number\n",
    "    p_lcritrey = np.ones(len(p_num)) * LRE\n",
    "    p_lcritrey = p_lcritrey.tolist()\n",
    "\n",
    "    # higher critical reynolds number\n",
    "    p_hcritrey = np.ones(len(p_num)) * HRE\n",
    "    p_hcritrey = p_hcritrey.tolist()\n",
    "\n",
    "    # summarize all data in a 2D-array\n",
    "    pipe_data = [p_num, p_diameter, p_tortuosity, p_rheight, p_lcritrey, p_hcritrey]\n",
    "    \n",
    "    return pipe_data\n",
    "\n",
    "def create_node_data(n_num, nodes_locations):\n",
    "    \"\"\"\n",
    "    Create nested list of node head data.\n",
    "    \n",
    "    Keyword arguments:\n",
    "      n_num -- node numbers, i.e. nbr_data[0]\n",
    "      nodes_locations -- node locations, i.e. nbr_data[2]\n",
    "    \n",
    "    Return: node head data\n",
    "    \"\"\"\n",
    "    # parametrization for all n nodes\n",
    "    # if head > 0: fixed head\n",
    "    # if head == -1: calculated head\n",
    "    n_head = np.ones((len(n_num))) * -1\n",
    "    n_head = n_head.tolist()\n",
    "\n",
    "    # search if the spring exists in the nodes\n",
    "    if idxs_spring in nodes_locations:\n",
    "        # get the position of spring node inside nbr_data\n",
    "        pos = nodes_locations.index(idxs_spring)\n",
    "        # assign the head to spring node\n",
    "        n_head[pos] = chb_spring\n",
    "    else:\n",
    "        raise Exception(\"Cannot find indices of spring in the indices of nodes!\")\n",
    "\n",
    "    node_data = [n_num, n_head]\n",
    "    \n",
    "    return node_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ab2c6d",
   "metadata": {},
   "source": [
    "## Generate the synthetic karst system using CFP MODE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a5242",
   "metadata": {},
   "source": [
    "### Set up the appropriate directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "047ffb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAUTION: You are using the development version of this package.\n"
     ]
    }
   ],
   "source": [
    "### Change the active directory to the model directory\n",
    "if not os.path.exists(path):\n",
    "    nb_dir = os.getcwd()\n",
    "    path = os.path.join(nb_dir)\n",
    "\n",
    "#set up a path to the yaml file\n",
    "yaml_file = os.path.join(nb_dir, \"single_settings.yaml\")\n",
    "catchment = pk.SKS(yaml_settings_file=yaml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d545ab0d",
   "metadata": {},
   "source": [
    "### Create a basic MODFLOW Model using FloPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "532a87cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the model object\n",
    "os.chdir(path)\n",
    "modelname = \"BS_CFP_singleCond_v1\"\n",
    "##Using CFPv2 here which has CADS support\n",
    "# to change, type in the correct FP version for the exe_name\n",
    "mf = flopy.modflow.Modflow(modelname, exe_name=\"cfpv2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbb5658",
   "metadata": {},
   "source": [
    "### Define the general domain characteristics (same as the complex CFP model with the pyKasso network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54632711",
   "metadata": {},
   "source": [
    "#### Spatial Domain Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a1a871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary layer elevation data and make copies of it\n",
    "topo = np.genfromtxt(r'bear_inputs\\BSDEM_10_10_230412.csv', delimiter=',')\n",
    "ztop = topo.copy()   #create a copy of the topography file\n",
    "topBedr = np.genfromtxt(r'bear_inputs\\model_bedr_topo10x10_smooth.csv', delimiter=',')\n",
    "ztopBedr = topBedr.copy()\n",
    "topOGPR = np.genfromtxt(r'topOGPR.csv', delimiter=',')\n",
    "ztopOGPR = topOGPR.copy()\n",
    "topOGCM = np.genfromtxt(r'topOGCM.csv', delimiter=',')\n",
    "ztopOGCM = topOGCM.copy()\n",
    "topODCH = np.genfromtxt(r'topODCH.csv', delimiter=',') #version calculated from the top OSTP data set\n",
    "ztopODCH = topODCH.copy()\n",
    "botODCH = np.genfromtxt(r'botODCH.csv', delimiter=',') #calculated from the topOSTP data set\n",
    "zbotODCH = botODCH.copy()\n",
    "\n",
    "topOSTP = np.genfromtxt(r\"bear_inputs/model_OSTP_top_10x10.csv\", delimiter=',')\n",
    "ztopOSTP = topOSTP.copy()\n",
    "topm = ztop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c938bfb",
   "metadata": {},
   "source": [
    "### Need to repair areas where the layers intersect, causing the model to crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0e04fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thickness0\n",
      "387.7175548477612\n",
      "387.713728476444\n",
      "thickness1\n",
      "thickness2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Repairing the topBedr layer with respect to the topm layer\n",
    "print(\"thickness0\")\n",
    "lay0_conflict = np.zeros((280,364))\n",
    "thickness0 = topm - ztopBedr\n",
    "for i in range(np.shape(thickness0)[0]):\n",
    "    for j in range(np.shape(thickness0)[1]):\n",
    "        if thickness0[i,j] <= 0:\n",
    "            lay0_conflict[i,j] = thickness0[i,j]\n",
    "np.savetxt('layer0conflict.csv', lay0_conflict, delimiter=',')\n",
    "\n",
    "topBedrfix = ztopBedr + lay0_conflict\n",
    "print(np.average(topBedr))\n",
    "print(np.average(topBedrfix))\n",
    "\n",
    "#re-calculate the layer conflict map between topBedrfix and topOGPR to get new layer_conflict array\n",
    "\n",
    "print(\"thickness1\")\n",
    "fixlay1_conflict = np.zeros((280,364))\n",
    "thickness1 = topBedrfix - ztopOGPR\n",
    "for i in range(np.shape(thickness1)[0]):\n",
    "    for j in range(np.shape(thickness1)[1]):\n",
    "        if thickness1[i,j] <= 0:\n",
    "            fixlay1_conflict[i,j] = thickness1[i,j]\n",
    "np.savetxt('fixlayer1conflict.csv', fixlay1_conflict, delimiter=',')\n",
    "\n",
    "#repairing the topOGPR layer with respect to the topBedrfix layer\n",
    "topOGPRfix = topOGPR + fixlay1_conflict\n",
    "\n",
    "print(\"thickness2\")\n",
    "fixlay2_conflict = np.zeros((280,364))\n",
    "thickness2 = topOGPRfix - ztopOGCM\n",
    "for i in range(np.shape(thickness2)[0]):\n",
    "    for j in range(np.shape(thickness2)[1]):\n",
    "        if thickness2[i,j] <= 0:\n",
    "            fixlay2_conflict[i,j] = thickness2[i,j]\n",
    "np.savetxt('fixlayer2conflict.csv', fixlay2_conflict, delimiter=',')\n",
    "\n",
    "topOGCMfix = topOGCM + fixlay2_conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8742449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# of rows, layers, and columns in the domain, int\n",
    "n_rows = 280\n",
    "n_cols = 364\n",
    "n_lays= 5\n",
    "#width of each cell along rows/columns\n",
    "delr = 10.\n",
    "delc = 10.\n",
    "\n",
    "Lx = n_cols*delr\n",
    "Ly = n_rows*delc\n",
    "\n",
    "#5 total layers with 6 unit top and bottom meshes\n",
    "topm = ztop #land surface elveation, top boundary of the model\n",
    "botm = np.full((n_lays,n_rows,n_cols), ztopBedr) # create arrays of default layer bottoms for each unit\n",
    "botm[0,:,:] = topBedrfix #top of the bedrock(top of the OGSV)\n",
    "botm[1,:,:] = topOGPRfix  #top of the OGPR (bottom of the OGSV)\n",
    "botm[2,:,:] = topOGCMfix  #top of the OGCM (bottom of the OGPR)\n",
    "botm[3,:,:] = ztopODCH # top of the ODCH (bottom of the OGCM)\n",
    "botm[4,:,:] = zbotODCH # bottom of the ODCH\n",
    "\n",
    "layer_elevations = [topm, botm[0], botm[1], botm[2], botm[3], botm[4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a4416e",
   "metadata": {},
   "source": [
    "repairing each layer in order to fix each cell with an error, we are making intersecting cells go to 0, as these intersections are the result of areas where the lower layers become discontinuous due to valley erosion\n",
    "##needs to be done sequentially with the fixed layers, as the impact of the layer above will change the thickness array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bca1db5",
   "metadata": {},
   "source": [
    "### Hydraulic characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db18607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Horizontal and vertical hydraulic conductivity of the Porous matrix [L/T]\n",
    "## For the start using a uniform hydraulic conductivity across the entire domain (all layers)\n",
    "#hk= 51891.95 ## in m/yr taken from the galena porosity spreadsheet (averaged over the OGSV, OGPR, OGCM)\n",
    "# need to have the Kh and the Kv in the proper units (m/yr for this model (see itmuni, lenuni))\n",
    "hk = np.full((n_lays,n_rows,n_cols),1) #create an array for the hk, vk of each of the layers (note, model will not run \n",
    "# if these values are not altered to be the appropriate magnitude)\n",
    "#horizontal hydraulic conductivity\n",
    "hk[0,:,:] = 71850\n",
    "hk[1,:,:] = 71850\n",
    "hk[2,:,:] = 71850\n",
    "hk[3,:,:] = 11975\n",
    "hk[4,:,:] = 100\n",
    "\n",
    "#vertical hydraulic conductivity\n",
    "vka = np.full((n_lays,n_rows,n_cols),1) # default array for the vertical hydraulic conductivity\n",
    "vka[0,:,:] = 718.5\n",
    "vka[1,:,:] = 718.5\n",
    "vka[2,:,:] = 718.5\n",
    "vka[3,:,:] = .11975\n",
    "vka[4,:,:] = .001\n",
    "#specific storage[1?L] and specific yield [-]\n",
    "ss = 0.00002\n",
    "sy = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ffd58",
   "metadata": {},
   "source": [
    "### Time discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a94b4cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the number of stress periods to be equal to the number of days in the recharge time series\n",
    "n_pers = 1\n",
    "\n",
    "#length (number of steps) of stress periods\n",
    "# this variable assumes a uniform time discretization, i.e. all stress periods have the same # of time steps except\n",
    "# for the first stationary time step\n",
    "perlen = 1\n",
    "\n",
    "#number of time steps in each stress period (integer array)\n",
    "n_stps = np.ones(n_pers)\n",
    "n_stps = n_stps.tolist()\n",
    "#ensure that the first stress period (stationary) has length of 1\n",
    "n_stps[0] = 1.0\n",
    "\n",
    "#list with \"False\" everywhere except the 0th element (which is set to 'True')\n",
    "    # to specify steady state (\"True\") or transient (\"False\")\n",
    "    #stress periods\n",
    "steady = np.ones(n_pers, dtype=bool)\n",
    "#ensure stationary first stress period\n",
    "steady[0] = 1\n",
    "\n",
    "#array of stress period numbers, 1-based indexing\n",
    "spers = np.arange(1, n_pers + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94f8751",
   "metadata": {},
   "source": [
    "### Boundary conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "794821a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Matrix head on the bottom (south) side (last row, all columns)\n",
    "## For the first setup, running the model with a single conduit with all flow toward the top of the model\n",
    "H_bot= 395.00\n",
    "\n",
    "#head value for the constant head node\n",
    "node_head_bc = 372.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ece5238",
   "metadata": {},
   "source": [
    "## Create CFP Input Files\n",
    "\n",
    "Conduit Network information\n",
    "*.nam-file of MODFLOW model gets updated at the end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a1d392",
   "metadata": {},
   "source": [
    "### CFPy-generate NBR input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3211e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear prior results\n",
    "clean_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9b0f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\"\" create the network array \"\"\"\n",
    "# 1 = conduit node location, 0 = pure matrix cell without conduit node\n",
    "\n",
    "network = np.zeros((280,364))\n",
    "network [:,150] = 1\n",
    "\n",
    "# generate elevations for the network\n",
    "# uniform elevation of 372 masl\n",
    "elev_nodes = np.ones_like(network) * 372\n",
    "\n",
    "# generate MODFLOW layer elevation information\n",
    "# here, single floats may be used if the layer elevations are uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03897529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' generating the .nbr-file '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate the network\n",
    "#validator = cfpy.preprocessing.GeneralValidator(network=network, elevations=elev_nodes)\n",
    "#valid_network = validator.validate_network()\n",
    "\n",
    "\"\"\" generating the .nbr-file \"\"\"\n",
    "# we use the same layer elevations here as in the MODFLOW model\n",
    "\n",
    "#validator.generate_nbr(\n",
    "#    path = path,\n",
    "#    nrows = n_rows,\n",
    "#    ncols = n_cols,\n",
    "#    nlays = n_lays,\n",
    "#    nplanes = 1,\n",
    "#    layer_elevations = layer_elevations\n",
    "#)\n",
    "\n",
    " #plot the network\n",
    "# TODO Können wir hier das schöne Bild wie in EX_02 generieren?\n",
    "#im = plt.imshow(valid_network)\n",
    "#plt.colorbar(im, shrink=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e5a3e7",
   "metadata": {},
   "source": [
    "#### Initialize nbr module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6987a31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time (.nbr file read): 0.02 s\n",
      "Elapsed time (write nbr data): 0.37 s\n"
     ]
    }
   ],
   "source": [
    "# NOTE: make sure there is only 1 .nbr-file in the active domain!!\n",
    "# if no or multiple .nbr-files are present, CFPy throws an error\n",
    "\n",
    "nbr = cfpy.nbr()\n",
    "\n",
    "# read model layer/node and conduit layer/node elevations\n",
    "\n",
    "# bot_elev has shape (n_layers, n_rows, n_cols)\n",
    "# cond_elev has shape (n_conduit_layers, n_rows, n_cols)\n",
    "# function looks for an .nbr-file, if none or more than one file is found, an error is raised\n",
    "# make sure to only have one .nbr-file in the working directory\n",
    "bot_elev, cond_elev = nbr.nbr_read()\n",
    "\n",
    "# create nbr-data\n",
    "nbr_data = nbr.nbr(bot_elev, cond_elev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98478ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nbr-data contains:\n",
    "#     0: node numbers\n",
    "#     1: plane numbers\n",
    "#     2: node locations\n",
    "#     3: conduit locations\n",
    "#     4: node neighbors\n",
    "#     5: tube numbers\n",
    "#     6: tube pairs\n",
    "#     7: tube neighbors\n",
    "\n",
    "# nbr data: locations in grid are indexed differently:\n",
    "#     MODFLOW: (LAY, ROW, COL)\n",
    "#     CFPy: (COL, ROW, LAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce594b2",
   "metadata": {},
   "source": [
    "## Plot Network (Currently turned off to speed up troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c87204d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#network = cfpy.plots.Network(elevs=[bot_elev, cond_elev], nbr_data=nbr_data)\n",
    "#plot = network.plot_network(text_shift=0.1, dpi=80, rot_x=15, rot_z=-100, plot_nums=False, kind=\"triangular\")\n",
    "#plt.savefig(\"network.jpg\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6058f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1526428",
   "metadata": {},
   "source": [
    "### CFPy parameterization of conduits/CFP Mode 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dc121e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make pipe parameterization lists\n",
    "\n",
    "#get pipe numbers\n",
    "p_num=nbr_data[5]\n",
    "\n",
    "# parametrization of all k pipes\n",
    "# assuming same characteristics for all pipes\n",
    "# lists for all conduit parametrization can be accessed individually to make differently parametrized pipes\n",
    "# e.g., p_diameter[13] = 0.45\n",
    "\n",
    "#CFP Position of spring, this should only be changed with the .yaml file, never directly here\n",
    "spring_position = catchment.get_outlets_data()\n",
    "UTME_spring = spring_position[0][0]\n",
    "UTMN_spring = spring_position[0][1]\n",
    "\n",
    "x_spring = int(np.floor(UTME_spring-catchment.settings[\"x0\"])/ delr)\n",
    "\n",
    "y_spring = int(np.floor(UTMN_spring-catchment.settings[\"y0\"] )/ delc)\n",
    "\n",
    "# global parameters\n",
    "\n",
    "DIA = 1.1\n",
    "TOR = 1.5\n",
    "KC  = 0.01\n",
    "LRE = 500\n",
    "HRE = 5000\n",
    "\n",
    "# diameter\n",
    "p_diameter = np.ones(len(p_num)) * DIA\n",
    "p_diameter = p_diameter.tolist()\n",
    "\n",
    "# tortuosity\n",
    "p_tortuosity = np.ones(len(p_num)) * TOR\n",
    "p_tortuosity = p_tortuosity.tolist()\n",
    "\n",
    "# roughness height\n",
    "p_rheight = np.ones(len(p_num)) * KC\n",
    "p_rheight = p_rheight.tolist()\n",
    "\n",
    "# lower critical reynolds number\n",
    "p_lcritrey = np.ones(len(p_num)) * LRE\n",
    "p_lcritrey = p_lcritrey.tolist()\n",
    "\n",
    "# higher critical reynolds number\n",
    "p_hcritrey = np.ones(len(p_num)) * HRE\n",
    "p_hcritrey = p_hcritrey.tolist()\n",
    "\n",
    "# summarize all data in a 2D-array\n",
    "pipe_data = [p_num, p_diameter, p_tortuosity, p_rheight, p_lcritrey, p_hcritrey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8bdecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lists for node head boundary conditions and tube-matrix exchange parameters\n",
    "\n",
    "# get node numbers\n",
    "n_num = nbr_data[0]\n",
    "\n",
    "# parametrization for all n nodes\n",
    "# if head > 0: fixed head\n",
    "# if head == -1: calculated head\n",
    "n_head = np.ones((len(n_num))) * -1\n",
    "n_head = n_head.tolist()\n",
    "\n",
    "# set individual node boundary conditions here\n",
    "# e.g., for n_head[-1] the last node has a constant head given by the variable node_head_bc\n",
    "# and for n_head[0] the first node has a constant head\n",
    "n_head[8] = node_head_bc\n",
    "\n",
    "# conduit wall conductivity in [m/d]\n",
    "# identical for all conduits\n",
    "# create list containing individual values to parametrize conduits individually\n",
    "kex = 12\n",
    "k_exchange = np.ones((len(n_num))) * kex\n",
    "k_exchange = k_exchange.tolist()\n",
    "\n",
    "# summarize parametrization in lists\n",
    "node_data = [n_num, n_head]\n",
    "kex_data = [n_num, k_exchange]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a64881",
   "metadata": {},
   "source": [
    "### Initialzie the CFP Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8823f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if CADS should not be used or standard CFP (CFPv1) is used set cads = None below!\n",
    "\n",
    "cfp = cfpy.cfp(mode = 1, # mode 1 == conduits, 2 == preferential flow layer (not supported), 3 == both (not supported)\n",
    "               nnodes = len(n_num), \n",
    "               npipes = len(p_num), \n",
    "               nlay = n_lays, \n",
    "               nbr_data = nbr_data, \n",
    "               geoheight = cond_elev, \n",
    "               sa_exchange = 1, \n",
    "               epsilon = 0.000001,\n",
    "               niter = 100, \n",
    "               relax = 1., \n",
    "               p_nr = 1., \n",
    "               cond_data = pipe_data, \n",
    "               n_head = node_data, \n",
    "               k_exchange = kex_data, \n",
    "               ncl = 0, \n",
    "               cl = 0, \n",
    "               ltemp = 25.,\n",
    "               condl_data = 0,\n",
    "               cads = None)\n",
    "\n",
    "# create list of strings\n",
    "cfp = cfp.cfp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea27cf",
   "metadata": {},
   "source": [
    "### CFPy - COC (Conduit output control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1966bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" initialize COC module \"\"\"\n",
    "\n",
    "coc = cfpy.coc(nnodes = len(nbr_data[0]),\n",
    "               node_numbers = nbr_data[0],\n",
    "               n_nts = 1,\n",
    "               npipes = len(nbr_data[5]), \n",
    "               pipe_numbers = nbr_data[5],\n",
    "               t_nts = 1)\n",
    "\n",
    "# create list of strings\n",
    "coc = coc.coc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ed1ca8",
   "metadata": {},
   "source": [
    "### CFPy = CRCH (conduit recharge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16afa717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_crch is list of length (n_nodes) specifying the direct recharge fraction for each node\n",
    "# initially set p_crch to 0 for all nodes (no direct recharge)\n",
    "p_crch = np.zeros((len(n_num))).tolist()\n",
    "\n",
    "# input direct recharge fraction (0 <= p_crch <= 1) for individual nodes\n",
    "p_crch[3] = 1.\n",
    "\n",
    "crch = cfpy.crch(iflag_crch = 1, \n",
    "                 nper = n_pers, \n",
    "                 node_numbers = nbr_data[0], \n",
    "                 p_crch = p_crch)\n",
    "\n",
    "# create list of strings\n",
    "crch = crch.crch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083dc653",
   "metadata": {},
   "source": [
    "## MODFLOW Input Files (FloPy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050fd974",
   "metadata": {},
   "source": [
    "### DIS (Discretization to create model grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "434fd754",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "value shape[0] != to self.shape[0] andvalue.shape[[1,2]] != self.shape[[1,2]] (1, 280, 364) (5, 280, 364)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m mbot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(bot_elev[\u001b[38;5;241m1\u001b[39m:][:][:])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create dis object:\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m dis \u001b[38;5;241m=\u001b[39m \u001b[43mflopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModflowDis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_lays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_pers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmtop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbotm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmbot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mperlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperlen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnstp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_stps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteady\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteady\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitmuni\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlenuni\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pyKasso2D_cfpy\\lib\\site-packages\\flopy\\modflow\\mfdis.py:202\u001b[0m, in \u001b[0;36mModflowDis.__init__\u001b[1;34m(self, model, nlay, nrow, ncol, nper, delr, delc, laycbd, top, botm, perlen, nstp, tsmult, steady, itmuni, lenuni, extension, unitnumber, filenames, xul, yul, rotation, proj4_str, start_datetime)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelc \u001b[38;5;241m=\u001b[39m Util2d(\n\u001b[0;32m    187\u001b[0m     model,\n\u001b[0;32m    188\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrow,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    192\u001b[0m     locat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_number[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    193\u001b[0m )\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop \u001b[38;5;241m=\u001b[39m Util2d(\n\u001b[0;32m    195\u001b[0m     model,\n\u001b[0;32m    196\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mncol),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m     locat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_number[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    201\u001b[0m )\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbotm \u001b[38;5;241m=\u001b[39m \u001b[43mUtil3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaycbd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbotm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbotm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munit_number\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperlen \u001b[38;5;241m=\u001b[39m Util2d(\n\u001b[0;32m    211\u001b[0m     model, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnper,), np\u001b[38;5;241m.\u001b[39mfloat32, perlen, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperlen\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m )\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnstp \u001b[38;5;241m=\u001b[39m Util2d(model, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnper,), np\u001b[38;5;241m.\u001b[39mint32, nstp, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnstp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pyKasso2D_cfpy\\lib\\site-packages\\flopy\\utils\\util_array.py:604\u001b[0m, in \u001b[0;36mUtil3d.__init__\u001b[1;34m(self, model, shape, dtype, value, name, fmtin, cnstnt, iprn, locat, ext_unit_dict, array_free_format)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(shape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    600\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mext_filename_base\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    601\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_base[k]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    602\u001b[0m         )\n\u001b[1;32m--> 604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mutil_2ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_2d_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pyKasso2D_cfpy\\lib\\site-packages\\flopy\\utils\\util_array.py:861\u001b[0m, in \u001b[0;36mUtil3d.build_2d_instances\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__value \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__value] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    862\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue shape[0] != to self.shape[0] and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    863\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue.shape[[1,2]] != self.shape[[1,2]] \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    864\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__value\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__value):\n\u001b[0;32m    867\u001b[0m     a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_2d(a)\n",
      "\u001b[1;31mException\u001b[0m: value shape[0] != to self.shape[0] andvalue.shape[[1,2]] != self.shape[[1,2]] (1, 280, 364) (5, 280, 364)"
     ]
    }
   ],
   "source": [
    "# Model grid:\n",
    "# Note: MODFLOW defaults to units of m/day\n",
    "# overall dimensions of domain (in x- and y-direction)\n",
    "Lx = n_cols*delr\n",
    "Ly = n_rows*delc\n",
    "mtop = np.array(bot_elev[0][:][:])\n",
    "mbot = np.array(bot_elev[1:][:][:])\n",
    "\n",
    "# Create dis object:\n",
    "dis = flopy.modflow.ModflowDis(mf, n_lays, n_rows, n_cols, n_pers, delr, delc, top=mtop, botm=mbot,\n",
    "                               perlen=perlen, nstp=n_stps, steady=steady, itmuni=5, lenuni=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a80f3b",
   "metadata": {},
   "source": [
    "### BAS (Basic) Assigns conduit head boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e30148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if ibound < 0: constant head, if = 0: inactive, if > 0: active.\n",
    "# create arrays to indicate active cells (ibound) and starting heads (H_init)\n",
    "# integer array of dim (z,y,x), makes all cells active \n",
    "ibound = np.ones((n_lays, n_rows, n_cols), dtype=np.int32)\n",
    "# replace leftmost and rightmost columns with -1 to indicate constant head \n",
    "#ibound[1,279,:] = -1 #turning off matrix constant head boundary\n",
    "\n",
    "strt = np.full((n_lays, n_rows,n_cols), topm-3) #initial hydraulic head 3 m below the land surface\n",
    "\n",
    "#make the last row the higher head value\n",
    "#strt[1,279,:] = H_bot   #turning this final row head boundary off\n",
    "\n",
    "bas = flopy.modflow.ModflowBas(mf, ibound=ibound, strt=strt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1408a227",
   "metadata": {},
   "source": [
    "### LPF (Layer Property Flow) :Horizontal and vertical flow params between cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d31a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only one of either the BCF, LPF, or HUF2 packages should be used to control flow between cells\n",
    "# Can also in this package set confined/unconfined (defaults to confined), cell-by-cell Ks as an array, \n",
    "# storage, specific yield, etc.\n",
    "# defaults to confined\n",
    "\n",
    "#0=confined, >0 = unconfined/convertible\n",
    "laytyp = [2, 2, 2, 2, 2]\n",
    "\n",
    "lpf = flopy.modflow.ModflowLpf(mf, laytyp=laytyp, hk=hk, vka=vka, ss=ss, sy=sy) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c2545",
   "metadata": {},
   "source": [
    "### OC (Output Control) Decides what outputs to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab1396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output control file using dictionary\n",
    "oc = flopy.modflow.ModflowOc(mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d34d4d8",
   "metadata": {},
   "source": [
    "### PCG (Preconditioned conjugate gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8741cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcg = flopy.modflow.ModflowPcg(mf, mxiter=40, iter1=10, ihcofadd=9999, relax=0.97,npcond=2, nbpol=2, iprpcg=5, mutpcg=0, hclose=12000, rclose=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e26064",
   "metadata": {},
   "source": [
    "### RCH (recharge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a38e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# recharge flux distributed over the top of the model - MODFLOW multiplies the fluxes by the horizontal area of the cells \n",
    "# to which they are applied to calculate the volumetric flux rates\n",
    "\n",
    "# generate recharge data\n",
    "rch_ts = np.ones_like(topm) *.8669 #based on 34.13 inches of toal rainfall in 2022. Doesn't account for snowmelt, need to calculate\n",
    "\n",
    "\n",
    "# flag, 1=rech only applied to top layer\n",
    "nrchop = 1\n",
    "# if non-zero, cell budget data will be saved\n",
    "ipakcb = 50\n",
    "# layer to which recharge is applied to (only used if nrchop=2)\n",
    "irch = 1\n",
    "\n",
    "# dictionary of recharge fluxes for each stress period\n",
    "rech = {}\n",
    "    \n",
    "for num, rech_in in enumerate(rch_ts):\n",
    "    \n",
    "    # make array (n_rows x n_cols) to store cell-by-cell recharge information\n",
    "    # apply recharge to all cells then apply direct recharge in relevant cells\n",
    "    rech_data = np.ones((n_rows, n_cols)) * rech_in\n",
    "    \n",
    "    # direct recharge cells have to be given explicitly\n",
    "    # such as\n",
    "    # rech_data[ROW, COL] = some_direct_recharge\n",
    "    \n",
    "    rech[num] = rech_data\n",
    "\n",
    "rch = flopy.modflow.mfrch.ModflowRch(mf, nrchop=nrchop, ipakcb=ipakcb, rech=rech, irch=irch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bc8875",
   "metadata": {},
   "source": [
    "## Derived Variables\n",
    "\n",
    "These parameters are derived from the given parameters above and relate to the spatial discretization of the conduit(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6748fec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the modflow indices for spring\n",
    "col_idx_spring, row_idx_spring = (x_spring, y_spring)\n",
    "idxs_spring = [int(col_idx_spring), int(row_idx_spring), 1]\n",
    "\n",
    "# expand elevations to array\n",
    "lay_elevs_array = [np.ones((n_rows, n_cols)) * layer_elevations[2],\n",
    "                   np.ones((n_rows, n_cols)) * layer_elevations[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e09f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(col_idx_spring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d670387",
   "metadata": {},
   "source": [
    "## Visualize the matrix, starting heads, and hydraulic conductivity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80d812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot cross-section view of model:\n",
    "row = 170     #row to plot on\n",
    "col = 65      #column to plot on\n",
    "\n",
    "#South-North:\n",
    "f,ax = plt.subplots(2,1, figsize=(25,15))                                     #create empty figure and axes objects\n",
    "xsec= flopy.plot.PlotCrossSection(model=mf, ax=ax[0], line={'column': col})  #plot cross-section along given column (change column # to see different locations)\n",
    "k  = xsec.plot_array(hk, cmap='copper', vmin=0, vmax=100000)                 #plot horizontal K as an array, with color range set manually to be consistent with other plots\n",
    "ax[0].plot(np.arange(delr/2,Ly,delr), strt[0,:,col])                         #plots starting heads as a line\n",
    "#ax[0].plot(np.arange(delr/2,Ly,delr), strt[1,:,col], color='blue')           #plots starting heads as a line\n",
    "bc = xsec.plot_ibound()                                                      #plot boundary conditions\n",
    "try: s  = xsec.plot_bc(\"STR\", color='skyblue')                                    #plot stream\n",
    "except: pass\n",
    "try: w = xsec.plot_bc(\"WEL\", color='red')                                         #plot wells (will only show wells at displayed column)\n",
    "except: pass\n",
    "try: g = m.plot_bc('GHB', color='goldenrod')                                      #plot head-dependent flow\n",
    "except: pass\n",
    "g  = xsec.plot_grid()                                                        #plot model grid\n",
    "ax[0].set_xlabel('y [m]')\n",
    "ax[0].set_ylabel('z [m]')\n",
    "ax[0].set_title('north-south cross-section')\n",
    "\n",
    "#East-West:\n",
    "xsec= flopy.plot.PlotCrossSection(model=mf, ax=ax[1], line={'Row': row})    #plot cross-ection along stream row\n",
    "k  = xsec.plot_array(hk, cmap='copper', vmin=-100, vmax=100000)                #plot heads as an array, with color range set manually to be consistent with other plots\n",
    "ax[1].plot(np.arange(delc/2,Lx,delc), strt[0,row,:])                        #plots starting heads as a line\n",
    "#ax[1].plot(np.arange(delc/2,Lx,delc), strt[1,row,:], color='blue')          #plots starting heads as a line\n",
    "bc = xsec.plot_ibound()                                                     #plot boundary conditions\n",
    "try: s  = xsec.plot_bc(\"STR\", color='skyblue')                                    #plot stream\n",
    "except: pass\n",
    "try: w = xsec.plot_bc(\"WEL\", color='red')                                        #plot wells (will only show wells at displayed row)\n",
    "except: pass\n",
    "try: g = m.plot_bc('GHB', color='goldenrod')                                     #plot head-dependent flow\n",
    "except: pass\n",
    "g  = xsec.plot_grid()                                                       #plot grid\n",
    "ax[1].set_xlabel('x [m]')\n",
    "ax[1].set_ylabel('z [m]')\n",
    "ax[1].set_title('east-west cross-section')\n",
    "\n",
    "plt.legend(handles=[matplotlib.patches.Patch(color='black',label='no-flow'),\n",
    "                    matplotlib.patches.Patch(color='peru',label='Kx'),\n",
    "                    matplotlib.patches.Patch(color='linen',label='confining unit'),\n",
    "                    matplotlib.patches.Patch(color='red',label='well'),\n",
    "                    matplotlib.patches.Patch(color='skyblue',label='stream'),\n",
    "                    matplotlib.lines.Line2D([],[], color='teal',label='head layer 0'),\n",
    "                    matplotlib.lines.Line2D([],[], color='blue',label='head layer 1')]) #add legend manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912be3b2",
   "metadata": {},
   "source": [
    "## Write input files and run the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5ddbcb",
   "metadata": {},
   "source": [
    "### MODFLOW Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2ede10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.write_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75ae7f",
   "metadata": {},
   "source": [
    "### CFP Mode 1 Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9845f9",
   "metadata": {},
   "source": [
    "#### CFPy, write_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057dc387",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = cfpy.write_input(modelname = modelname,\n",
    "                               data_strings = [coc, crch, cfp],\n",
    "                               file_extensions = ['coc', 'crch', 'cfp'])\n",
    "\n",
    "# write CFP input files\n",
    "input_files.write_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51edcb04",
   "metadata": {},
   "source": [
    "### CFPy update_nam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a5da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nam = cfpy.update_nam(modelname = modelname,\n",
    "                      mode = 1,\n",
    "                      cfp_unit_num = 52,\n",
    "                      crch_unit_num = 53,\n",
    "                      coc_unit_num = 54)\n",
    "\n",
    "# update existing .nam file\n",
    "nam.update_nam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c40e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd34c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(nbr_data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc465b38",
   "metadata": {},
   "source": [
    "## Run MODFLOW 2005 CFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a9c49fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, remove previous results\n",
    "clean_results()\n",
    "\n",
    "#Initialize success counter\n",
    "n_success = 0\n",
    "\n",
    "# initialize list for unsuccessful runs\n",
    "not_success = []\n",
    "\n",
    "# Define the number of model variants\n",
    "n_variants = 10\n",
    "\n",
    "# store 9 randomly selected networks for plotting later\n",
    "# np.random.seed(2345678)\n",
    "# rnd = np.array([1, 10, 11, 16, 20, 25, 77, 90, 93])\n",
    "# rnd_ = np.reshape(rnd, (3, 3))\n",
    "networks_plot = []\n",
    "\n",
    "for i in range(n_variants):\n",
    "    print(\"Running model variant \", i)\n",
    "    # Generate the continuum\n",
    "    mf.write_input()\n",
    "    \n",
    "    #GENERATE THE CFP Model\n",
    "    validator, valid_network = create_network()\n",
    "    create_nbr(validator)\n",
    "    #nbr_data, cond_elev = read_nbr()\n",
    "    nbr_data, elevs = read_nbr()\n",
    "    pipe_data = create_pipe_data(nbr_data[5])\n",
    "    node_data = create_node_data(nbr_data[0], nbr_data[2])\n",
    "    kex_data = create_kex_data(nbr_data[0])\n",
    "    cads_data = create_cads_data(nbr_data[0])\n",
    "    cfp = init_cfp_module(nbr_data, elevs[1], pipe_data, node_data, kex_data, cads_data)\n",
    "    #cfp = init_cfp_module(nbr_data, cond_elev, pipe_data, node_data, kex_data, cads_data)\n",
    "    coc = init_coc_module(nbr_data[0], nbr_data[5])\n",
    "    crch = init_crch_module(nbr_data[0])\n",
    "    input_files = cfp_write_input(coc, crch, cfp)\n",
    "\n",
    "    #UPDATE THE NAME FILE\n",
    "    nam = cfp_update_nam()\n",
    "    \n",
    "    #RUN THE MODEL\n",
    "    success, buff = mf.run_model(silent=False)\n",
    "    \n",
    "    if success:      \n",
    "        n_success = n_success + 1\n",
    "        network = cfpy.plots.Network(elevs=elevs, nbr_data=nbr_data)\n",
    "        networks_plot.append(network)\n",
    "        plot_network(network, i)\n",
    "        store_results(i)\n",
    "    else:\n",
    "        not_success.append(i)\n",
    "        \n",
    "print('Computational loop finished for ', n_variants, ' variants. ', n_success, 'variants solved successfully.')\n",
    "print('Variants with unsuccessful runs: {}'.format(not_success))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1b52b8",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fdc11e",
   "metadata": {},
   "source": [
    "### Process the information for the MODFLOW Continuum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69288327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "import flopy.utils.binaryfile as bf\n",
    "\n",
    "# get cell head information\n",
    "# choose location to measure heads (lay,row,col), zero-based indexing\n",
    "obs_loc = (0,1,2)\n",
    "\n",
    "# read the list, binary files\n",
    "lst = flopy.utils.MfListBudget(modelname+'.list')\n",
    "hds = bf.HeadFile(modelname+'.hds')\n",
    "# return a list of head and budget print times\n",
    "h_times = hds.get_times()\n",
    "b_times = lst.get_times()\n",
    "\n",
    "heads = []\n",
    "for t in h_times:\n",
    "    heads.append(hds.get_data(totim=t))\n",
    "heads = np.asarray(heads)\n",
    "\n",
    "budgets = []\n",
    "for t in b_times:\n",
    "    budgets.append(lst.get_data(totim=t, incremental=True))\n",
    "\n",
    "# get a time series of heads at a specific location\n",
    "obs_ts = hds.get_ts(obs_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacb374c",
   "metadata": {},
   "source": [
    "### Process the information for CFP Mode1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991066f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = cfpy.postprocessing.FileReader(\n",
    "    modelname=modelname\n",
    ")\n",
    "\n",
    "node_data, tube_data = [], []\n",
    "\n",
    "node_nums = [1, 2, 5]\n",
    "tube_nums = [1, 2, 4]\n",
    "\n",
    "for node in node_nums:\n",
    "    node_df, tube_df = fr.read_output(node_num=node, tube_num=None)\n",
    "    node_data.append(node_df)\n",
    "    \n",
    "for tube in tube_nums:\n",
    "    node_df, tube_df = fr.read_output(node_num=None, tube_num=tube)\n",
    "    tube_data.append(tube_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fccfc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Lok at this imported node time series data\n",
    "node_data[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5cbb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at the imported tube time series data\n",
    "tube_data[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e058e2e",
   "metadata": {},
   "source": [
    "## Generate Plots for Visualization (Turned off for troubleshooting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f81402",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Generate more plots (spatially distributed information)\n",
    "#network = cfpy.plots.Network(elevs=[bot_elev, cond_elev], nbr_data=nbr_data)\n",
    "#plot = network.plot_results(heads=heads, time=0, layer=2, text_shift=0.1, dpi=100, rot_x=25, rot_z=120, plot_nums=False, n_contours=20, alpha=0.01)\n",
    "#plt.savefig(\"results_network.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f3327",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(12,8))\n",
    "\n",
    "im = ax1.contourf(heads[0,3,:,:])\n",
    "ax1.invert_yaxis()\n",
    "fig.colorbar(mappable=im)\n",
    "\n",
    "topo = ax2.contourf(topm)\n",
    "ax2.invert_yaxis()\n",
    "fig.colorbar(mappable=topo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
